
我们在前边实现了PBR的**直接光照**，在那部分我们大胆的假设了对于Shading Point p，除了光源入射的ωi方向以外，其它可能入射的Radiance贡献均为0，这也是为什么称为直接光照
接下来，我们会考虑ωi以外方向的部分，这部分的贡献是不是由光源直接照射过来的，而是由其他环境表面吸收剩余弹射过来的，也就是环境光照部分，这一部分也称为**间接光照**


## 0、IBL
IBL全称Image Based Lighting，译为基于图像的光照，它是一类技术的总称
IBL通常使用Cubemap的每个像素作为光源，将它带入渲染方程中使用，后续我们会详细讲解

上边我们提到了上节讲解的直接光照部分，通过大胆假设，我们将半球的入射光ωi方向的Radiance的总贡献的**积分**分解为了遍历已知所有光源的**累加**
但是对于环境光照，我们不能假设只有ωi方向有贡献了，所以又变回了积分问题
对于这个积分问题不是很简单，为了解决我们提出了两个要求：
- 给定任意方向ωi，需要一些方法获取这个方向的Radiance
- 在解决积分时需要快速（Realtime）

IBL的处理方法是：
- 将第一部分使用预计算的方式解决（PreComputed）
- //Todo

说太多也没有用，对于计算环境光照，我们还需回到反射方程：
![3.IBL_image_1](assets/3.IBL_image_1.png)
BRDF的漫反射kd和镜面反射ks是相互独立的，我们可以将它们拆分开：
![3.IBL_image_2](assets/3.IBL_image_2.png)

接下来我们会将漫反射和镜面反射的表面分开讲解，一一讲述如何解决这两种的环境光照解决方法
//编者注：LearnOpenGL对于IBL的讲解可能没那么容易懂（具体说就是知道让你这么做，为啥这么做其实没有详细解释），笔者建议查阅GAMES202-IBL部分理解 [L5：SDF Shadow, IBL](../../../../../【7.CouseNote】/【GraphicCourse】/【GAMES202】/L5：SDF%20Shadow,%20IBL.md)

## 拆分思想
**//为了更好的理解，这里我们不会完全按照LearnOpenGL的原文逐一讲解**
**//笔者将根据GAMES202的IBL部分引入LearnOpenGL的内容，前部分不会特别详细的整理，我们尽量用简单的话概括，具体可以参考202或者上边笔记链接**
**//总的来说，GAMES202的讲解思路是将Ligting和BRDF拆分考虑讲解，LearnOpenGL是将漫反射和镜面反射拆分考虑讲解**

我们先看看最上边的反射方程，如果用GAMES202的渲染方程就是下边这样：
![3.IBL_image_3](assets/3.IBL_image_3.png)
- 蓝色部分是Lighting
- 橙色部分是BRDF
- 打叉的是Visibility，可见性，我们这里不考虑可见性

所以解决环境光照带入渲染方程就是：解决Lighting和BRDF相乘在半球领域的积分（不考虑可见性）

### Lighting项
我们可以用一个近似的方式将积分相乘近似为各自积分再相乘，这种类型的函数我们称为**product integral**，类似下边这样：
![3.IBL_image_4](assets/3.IBL_image_4.png)
这个近似在以下情况下比较准确：
- gx的积分域（support）较小
- gx的值比较smooth时


利用上边的近似，对应在上边的渲染方程中就可以拆分Lighting和BRDF了

我们先看左边的Lighting部分
我们不妨先用一些语言描述这个部分：
- 拆分出来了，所以和BRDF无关
- Lighting表示在半球上，brdf覆盖Lobe（可以理解为brdf的可视化）的某个区域积分起来再normalize
- 这个操作是可以预计算的，也就是对环境光照的image进行滤波操作


我们举个例子来看：
![3.IBL_image_5](assets/3.IBL_image_5.png)
- i = 观察方向
- 左边
    - 红色箭头是对于点p可能入射的方向ωi
    - 蓝色范围 = lobe
    - 要想计算环境光照，就相当于在lobe周围根据roughness分布采样，然后加权平均
- 右边
    - 蓝色箭头是反射方向
    - 红色半球上的橙色区域 = 经过预计算的image
    - 想要利用IBL的思想得到环境光照，就是在反射方向对预计算的image进行一次查询


**注：**
- 上边例子中的lobe为表面是Glossy情况的情况，漫反射的lobe是散布整个半球的
- 对于表面的描述，我们会用以下三类：
    - Diffuse，漫反射
    - Glossy，介于两者之间
    - Specular，镜面反射
- **对于漫反射**，我们认为lobe的中心方向是法线方向，所以漫反射根据法线方向查询


### BRDF项
对于brdf部分，第一反应也是进行预计算
但是brdf部分的复杂度相当的高，以roughness，Fresnel的rgb+曲线算的话，已经五维了

我们可以具体看看取Schlick's approximation的F项和Beckmann的D项的情况：
![329x137](assets/3.IBL_image_6.png)
![411x164](assets/3.IBL_image_7.png)
- R0 = 基础反射率
- θ夹角
- α = roughness

这样可以降到三维
到此为止我们仍然不满足，对于F项，我们可以把R0拆到积分外边（具体拆分过程省略，详细情况games202Lecture5 [L5：SDF Shadow, IBL](../../../../../【7.CouseNote】/【GraphicCourse】/【GAMES202】/L5：SDF%20Shadow,%20IBL.md)）
![605x121](assets/3.IBL_image_8.png)
这样我们就满意了，现在BRDF部分是一个关于θ和α的积分了
对于这两个维度，我们可以PreComputed出来，通过一张LUT（LookUpTable，查找表）存储
![296x238](assets/3.IBL_image_9.png)
//想必这张图你在刷各种资料的时候见过

## 1、漫反射IBL
### 预计算/立方体贴图卷积
上述在结合GAMES202的讲解中，我们知道如何查询环境光照的结果
具体到LearnOpenGL这部分，我们要解决的就是如何将结果进行**预计算**

首先先列出漫反射的反射方程：
![269x63](assets/3.IBL_image_10.png)
我们知道漫反射的lambert项kd是常数（kd折射率，c颜色，π都是常数）
所以可以将常数系数分离出来：
![298x58](assets/3.IBL_image_11.png)
现在有关的就还有p和ωi了
对于点p，我们认为它处于半球的中心，也就是预计算之后image的中心（预计算后的图称为irradiance map，辐照度图）
这样就是一个关于ωi的积分项了，也就是ωi方向环境光照的总Radiance
我们现在要做的就是根据这个公式，使用预计算的方式对环境贴图进行预处理或者说卷积，**结果的每个texel都存着这个积分的结果**

![352x259](assets/3.IBL_image_12.png)


#### HDR
**HDR存储**
我们再打一个叉，前边实现PBR的直接光照时我们说了HDR对PBR的重要性。
如果对于预计算的话，需要考虑的就是：**如何将HDR的光照接管存储的环境贴图中**

**.hdr**
一般我们使用的Cubemap都是ldr格式，精度范围是0~1，所以这里就需要一个适合Irradiance Map的格式，它的拓展名是.hdr
这个格式的六个面都是float，允许存储hdr的数据
具体点讲，他并不是每个通道都用32位，而是每个通道8位，a通道存放指数，这样一来虽然有精度损失，但也有很高的效率，不过要记得在代码中对每个通道做解析来获取等效的float值
一个hdr图类似下边这样：
![471x241](assets/3.IBL_image_13.png)
你可以从下边这个网站找到更多： https://polyhaven.com/hdris
一些DCC中也内置了，路径大概如下：
```cpp
//应该是旧版的，不是被Adobe收购后的，收购后的貌似改到startasset部分了
//[SD]:
SubstanceDesigner\resources\view3d\maps
//[SP]:
SubstancePainter\resources\shelf\allegorithmic\environments\Exterior
//[UESourceCOde]:
UESourceCode\UnrealEngine\Engine\Source\ThirdParty\openexr\openexr-3.1.5\src\test\OpenEXRTest
```

上边的hdr图看起来有点扭曲，也不是之前看的六面cubemap
这是因为上图是这是一张从球体投影到平面上，以支持我们轻松的将环境信息存储到一张Equirectangular Map（等距柱状投影图）中
//值得注意的是，它的水平视角附近分辨率较高，底部和顶部较低（这在大部分情况下都是不错的折中方案了）

stb_imag支持将hdr直接加载为float数组，通过stb_image加载hdr的情况类似下边这样：
```cpp
//stb_image.h 自动将 HDR 值映射到一个浮点数列表：默认情况下，每个通道32位，每个颜色 3 个通道

#include "stb_image.h"
[...]

stbi_set_flip_vertically_on_load(true);
int width, height, nrComponents;
float *data = stbi_loadf("newport_loft.hdr", &width, &height, &nrComponents, 0);
unsigned int hdrTexture;
if (data)
{
    glGenTextures(1, &hdrTexture);
    glBindTexture(GL_TEXTURE_2D, hdrTexture);
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB16F, width, height, 0, GL_RGB, GL_FLOAT, data); 

    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);

    stbi_image_free(data);
}
else
{
    std::cout << "Failed to load HDR image." << std::endl;
}  
```


#### ### From Equirectangular to Cubemap-从等距柱状投影图到Cubemap
直接采样等距柱状投影图也是可以的，但是这个操作比较昂贵
这里我们先将这个图转为cubemap，再采样Cubemap

具体做法就是：渲染一个cube，从内部将等距柱状投影图投影到cube的每个面，再将cube的6个面构造为Cubemap
Shader代码如下：
```cpp
//VS
#version 330 core
layout (location = 0) in vec3 aPos;

out vec3 localPos;

uniform mat4 projection;
uniform mat4 view;

void main()
{
    localPos = aPos;  
    gl_Position =  projection * view * vec4(localPos, 1.0);
}


//FS
#version 330 core
out vec4 FragColor;
in vec3 localPos;

uniform sampler2D equirectangularMap;

const vec2 invAtan = vec2(0.1591, 0.3183);
vec2 SampleSphericalMap(vec3 v)
{
    vec2 uv = vec2(atan(v.z, v.x), asin(v.y));
    uv *= invAtan;
    uv += 0.5;
    return uv;
}

void main()
{       
    vec2 uv = SampleSphericalMap(normalize(localPos)); // make sure to normalize localPos
    vec3 color = texture(equirectangularMap, uv).rgb;

    FragColor = vec4(color, 1.0);
}
```
将等距柱状投影图映射到cube效果类似下边这样：
![380x283](assets/3.IBL_image_14.png)

为了将它存为Cubemap，我们需要渲染6次，将每个独立面通过FrameBuffer记录并存储
```cpp
//FrameBuffer
unsigned int captureFBO, captureRBO;
glGenFramebuffers(1, &captureFBO);
glGenRenderbuffers(1, &captureRBO);

glBindFramebuffer(GL_FRAMEBUFFER, captureFBO);
glBindRenderbuffer(GL_RENDERBUFFER, captureRBO);
glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, 512, 512);
glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, captureRBO);

//alloc memory for cubemap
unsigned int envCubemap;
glGenTextures(1, &envCubemap);
glBindTexture(GL_TEXTURE_CUBE_MAP, envCubemap);
for (unsigned int i = 0; i < 6; ++i)
{
    // note that we store each face with 16 bit floating point values
    glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, GL_RGB16F, 
                 512, 512, 0, GL_RGB, GL_FLOAT, nullptr);
}
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);

//6 face
glm::mat4 captureProjection = glm::perspective(glm::radians(90.0f), 1.0f, 0.1f, 10.0f);
glm::mat4 captureViews[] = 
{
   glm::lookAt(glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3( 1.0f,  0.0f,  0.0f), glm::vec3(0.0f, -1.0f,  0.0f)),
   glm::lookAt(glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(-1.0f,  0.0f,  0.0f), glm::vec3(0.0f, -1.0f,  0.0f)),
   glm::lookAt(glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3( 0.0f,  1.0f,  0.0f), glm::vec3(0.0f,  0.0f,  1.0f)),
   glm::lookAt(glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3( 0.0f, -1.0f,  0.0f), glm::vec3(0.0f,  0.0f, -1.0f)),
   glm::lookAt(glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3( 0.0f,  0.0f,  1.0f), glm::vec3(0.0f, -1.0f,  0.0f)),
   glm::lookAt(glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3( 0.0f,  0.0f, -1.0f), glm::vec3(0.0f, -1.0f,  0.0f))
};

// convert HDR equirectangular environment map to cubemap equivalent
equirectangularToCubemapShader.use();
equirectangularToCubemapShader.setInt("equirectangularMap", 0);
equirectangularToCubemapShader.setMat4("projection", captureProjection);
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, hdrTexture);

glViewport(0, 0, 512, 512); // don't forget to configure the viewport to the capture dimensions.
glBindFramebuffer(GL_FRAMEBUFFER, captureFBO);
for (unsigned int i = 0; i < 6; ++i)
{
    equirectangularToCubemapShader.setMat4("view", captureViews[i]);
    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, 
                           GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, envCubemap, 0);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

    renderCube(); // renders a 1x1 cube
}
glBindFramebuffer(GL_FRAMEBUFFER, 0);  
```

你可以将这个结果debug，作为skybox输出查看：
```cpp
//VS
#version 330 core
layout (location = 0) in vec3 aPos;

uniform mat4 projection;
uniform mat4 view;

out vec3 localPos;

void main()
{
    localPos = aPos;

    mat4 rotView = mat4(mat3(view)); // remove translation from the view matrix
    vec4 clipPos = projection * rotView * vec4(localPos, 1.0);

    gl_Position = clipPos.xyww;//经过透视除法，depth always = 1
}

//FS
#version 330 core
out vec4 FragColor;

in vec3 localPos;

uniform samplerCube environmentMap;

void main()
{
    vec3 envColor = texture(environmentMap, localPos).rgb;

    envColor = envColor / (envColor + vec3(1.0));
    envColor = pow(envColor, vec3(1.0/2.2)); 

    FragColor = vec4(envColor, 1.0);
}

//CPU
glDepthFunc(GL_LEQUAL);

```
![624x460](assets/3.IBL_image_15.png)

#### Cubemap convolution
终于到了如何进行预处理了
先明确一下我们的主要目标：计算所有间接漫反射的积分，结果存在一张Irradiance Map中

回顾一下这部分开头我们想精确的计算lighting部分需要如何做：在lobe周围根据roughness分布采样，然后加权平均
这个操作正对应我们做的卷积操作，它定义了IBL中的PreFiltering：取任意一个点的周围范围，加权平均再写回
这个范围或者说滤波的kernel，取决于brdf占多大

有很多方法对环境贴图进行卷积，LearnOpenGL这里使用的方法是：为每个texel在半球Ω范围生成固定数量的采样向量，围绕采样向量方向进行采样并加权平均
注：
- 生成的采样向量均匀的分布在半球
- 采样向量数量越多，近似越准确

对于dωi的立体角，我们用球坐标的θ和Φ来表示，其中θ是inclination zenith angle（倾斜角），Φ是polar azimuth angle（航向角）
- θ的采样范围是竖直的弧线代表的角度，即0~1/2π
- Φ的采样范围是水平的弧线代表的角度，即0~2π
![497x276](assets/3.IBL_image_16.png)
- 此时球面上的橙色单位面积就代表我们每次采样的结果
- 因为球的一般性质，当采样区域靠近顶部时，倾斜角θ变大，采样区域会变小，我们使用sinθ来描述采样区域的贡献权重

那么此时的反射方程可以如下表示：
![598x68](assets/3.IBL_image_17.png)
用理论部分的离散样本求解的黎曼和思路，我们可以把积分转换为以下版本：
![595x74](assets/3.IBL_image_18.png)

在给定积分的球坐标系下离散采样半球，对应的FS如下：
```cpp
vec3 irradiance = vec3(0.0);  

vec3 up    = vec3(0.0, 1.0, 0.0);
vec3 right = normalize(cross(up, normal));//通过法线和up叉乘计算right vec
up         = normalize(cross(normal, right));//重新叉乘出up

float sampleDelta = 0.025;//采样delta，越小采样次数越多
float nrSamples = 0.0; //采样计数
for(float phi = 0.0; phi < 2.0 * PI; phi += sampleDelta)//倾斜角范围0~2π
{
    for(float theta = 0.0; theta < 0.5 * PI; theta += sampleDelta)//航向角范围0~1/2 π
    {
        //球面坐标转到笛卡尔坐标系 (in tangent space)
        //x = sinθ * cosΦ
        //y = sinθ * sinΦ
        //z = cosθ
        vec3 tangentSample = vec3(sin(theta) * cos(phi),  sin(theta) * sin(phi), cos(theta));
        
        // tangent space to world
        vec3 sampleVec = tangentSample.x * right + tangentSample.y * up + tangentSample.z * N; 

        irradiance += texture(environmentMap, sampleVec).rgb * cos(theta) * sin(theta);
        nrSamples++;
    }
}
irradiance = PI * irradiance * (1.0 / float(nrSamples));

```

CPU端：
```cpp
//Create IrradianceMap
unsigned int irradianceMap;
glGenTextures(1, &irradianceMap);
glBindTexture(GL_TEXTURE_CUBE_MAP, irradianceMap);
for (unsigned int i = 0; i < 6; ++i)
{
    glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, GL_RGB16F, 32, 32, 0, 
                 GL_RGB, GL_FLOAT, nullptr);
}
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);

//由于Irradiance的信息都是低频信息，所以分辨率给32x32即可
glBindFramebuffer(GL_FRAMEBUFFER, captureFBO);
glBindRenderbuffer(GL_RENDERBUFFER, captureRBO);
glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, 32, 32); 

irradianceShader.use();
    irradianceShader.setInt("environmentMap", 0);
    irradianceShader.setMat4("projection", captureProjection);
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_CUBE_MAP, envCubemap);

    glViewport(0, 0, 32, 32); // don't forget to configure the viewport to the capture dimensions.
    glBindFramebuffer(GL_FRAMEBUFFER, captureFBO);
    for (unsigned int i = 0; i < 6; ++i)
    {
        irradianceShader.setMat4("view", captureViews[i]);
        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, 
                           GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, irradianceMap, 0);
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

        renderCube();
    }
    glBindFramebuffer(GL_FRAMEBUFFER, 0);

```

将这个Irradiance直接作为skybox输出效果类似下边这样：
![468x411](assets/3.IBL_image_19.png)


### Indirect Irradiance Lighting 间接光照
在完成Irradiance Map的处理后，我们就要着手进行完整的Shading了
Irradiance Map代表周围间接光的结果，在光照模型中作为环境光照部分

Shader中采样环境光照的代码如下：
```cpp
uniform samplerCube irradianceMap;

void main()
{
    
    //反射，折射
    //对于反射
        //我们使用N代表H
        //并使用Sébastien Lagarde提出的Fresnel-Schlick中加入粗糙度修正粗糙非金属表面的反射
    vec3 kS = fresnelSchlickRoughness(max(dot(N, V), 0.0), F0, roughness);
    vec3 kD = 1.0 - kS;
    
    //对于漫反射，使用N采样IrradianceMap
    vec3 irradiance = texture(irradianceMap, N).rgb;
    vec3 diffuse    = irradiance * albedo;
    vec3 ambient    = (kD * diffuse) * ao; 
}

vec3 fresnelSchlickRoughness(float cosTheta, vec3 F0, float roughness) 
{ 
    return F0 + (max(vec3(1.0 - roughness), F0) - F0) * pow(1.0 - cosTheta, 5.0); 
}

```
![512x448](assets/3.IBL_image_20.png)

到此为止，你可能会发现金属度较高的金属表面看起来仍然不太正常
在理论部分我们说过金属表面没有漫反射
目前为止我们并没有环境光照的反射部分，都是折射，后续我们会探讨一下如何解决环境光照的反射部分

## 2.镜面反射IBL

接下来是镜面反射即反射部分的间接光照部分
我们显示回到镜面反射ks的反射方程：
![502x83](assets/3.IBL_image_21.png)

对于反射的ks来说，它并不像kd一样好解决，它不仅受入射光方向影响，也受到观察方向影响
如果要解决这个积分的话，需要考虑所以Incident Light和View，计算量是非常大的
Epic Games在UE中提出了一个解决方案，称为**分割求和近似**（split sum approximation）
这种方法将间接光的镜面反射分为了单独的两个部分，这样一来我们可以单独PreComputed然后再求和，作为环境镜面反射IBL
拆分后的结果如下：
![509x99](assets/3.IBL_image_22.png)

### 0.镜面反射IBL思路
#### PreFiltering EnvironmentMap
第一部分为PreFilteringEnvironmentMap， Filtering就是滤波，也就是模糊
这部分考虑了roughness，不同的roughness代表这不同程度的模糊，这些一般利用mipmap存到一个Cubemap中
![394x157](assets/3.IBL_image_23.png)
使用Cook-Torrance 的D项生成采样样本及其散射量，这个函数接收n和v作为输入
由于在预处理时无法获取v的方向，**Epic采用了进一步近似：假设v方向 = 输出样本方向ωo**
伪代码如下：
```cpp
vec3 N = normalize(w_o); 
vec3 R = N; 
vec3 V = R;
```
这样近似的情况下，掠角的镜面反射不是很好，不过这也是可以接受的了
![543x219](assets/3.IBL_image_24.png)


#### 镜面反射积分BRDF
第二部分为镜面反射积分中的BRDF
如果假设入射的Radiance在所有方向都是纯白的（即L(p,x)=1.0），就能预计算BRDF在给定roughness和θ（n和光线方向ωi的点乘）的情况下的结果
Epic 将预计算的结果存在名为BRDF integration map（BRDF积分图），这张图就是一张LUT，它记录了不同Roughness下各法线与light direction组合的响应
这张图的R通道是Scale ，G通道是Bias，两者共同组成表面的Fresnel response，即右边部分
在生成lUT的时候，以BRDF的输入n·ωi（范围在0~1）作为u（横坐标），以Roughness为v（纵坐标）

#### 镜面反射积分
有了上边两部分，就可以结合起来获得镜面反射的积分了
```cpp
//用Roughness索引lod值
float lod = getMipLevelFromRoughness(roughness);
//采样PreFiltering的环境贴图
vec3 prefilteredColor = textureCubeLod(PrefilteredEnvMap, refVec, lod);
//计算环境镜面反射BRDF
vec2 envBRDF = texture2D(BRDFIntegrationMap, vec2(NdotV, roughness)).xy;
vec3 indirectSpecular = prefilteredColor * (F * envBRDF.x + envBRDF.y)
```


### 1.PreFiltering HDR environment map
上边简单的讲解了思路，接下来我们着手进行实际的操作了

PreFiltering和漫反射部分的卷积相似，区别在于它需要考虑Roughness，并将Roughness不同情况下的结果存在Cubemap的不同Mip层中
首先创建一个cubemap：
```cpp
unsigned int prefilterMap;
glGenTextures(1, &prefilterMap);
glBindTexture(GL_TEXTURE_CUBE_MAP, prefilterMap);
for (unsigned int i = 0; i < 6; ++i)
{
    glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, GL_RGB16F, 128, 128, 0, GL_RGB, GL_FLOAT, nullptr);//128的分辨率满足大部分情况，对于汽车车漆反射这样的高要求可以增加分辨率
}
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);//三线性过滤
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR);

glGenerateMipmap(GL_TEXTURE_CUBE_MAP);//记得mipmap
```

回顾一下漫反射部分的预积分计算，我们生成的采样样本均匀的分布在半球上，这是因为对于漫反射，或者说越粗糙的表面，光线反射的lobe越是接近覆盖整个半球的
我们直接把GAMES202部分笔记截图放上来：
![3.IBL_image_25](assets/3.IBL_image_25.png)
所以对于镜面的环境光照预计算，均匀的分布样本显然是不合适的
一个直觉的想法就是根据Lobe的形状在其周围分布样本，然后加权平均，由此我们也引出了一个概念：**重要性采样**

#### 蒙特卡洛积分和重要性采样
蒙特卡洛积分是一种数学结构，是统计和概率论的组合，它可以帮助我们离散地解决人口统计问题，而不用计算所有人
我们通过一个具体的例子来讲解：
            假设我们需要统计全国的平均身高
            **穷举**：测量所有人的身高，然后取平均（力大砖飞，但是力再大也解决不了了）
            **大数定律**：找到一个小的完全随机(无偏)的人口集，取平均（并非绝对精确，但会得到一个接近的答案）
            **蒙特卡洛积分思想**：挑选一个较小的真正随机的样本N，随着样本的数增加，结果也会越来越接近真实的值

可以看到蒙特卡洛积分是在大数定律的基础上，采样相同的方法求解积分：不为所有值求解积分，而是从总体中随机挑选样本N生成采样值求平均。随着N的增加，结果也会越来越接近积分的精确结果
![253x70](assets/3.IBL_image_26.png)

具体来说就是：求解积分，我们需要在a~b上采样N个随机样本，然后除以样本数取平均
**probability density function 概率密度函数**，简称pdf，用来描述特定样本在整个样本集上发生的概率，范围也就是0~1了
还拿平均身高的例子来看：
![353x215](assets/3.IBL_image_27.png)
- 1.70左右的人口可能性更高，1.50的概率更低

这也带来了一个蒙特卡洛积分的问题：有些样本（比如1.70）比其他样本出现的概率更高
一般会在蒙特卡洛估计时根据pdf将采样值进行修正（乘以或者除以概率），那么进行估算时的样本就是均匀分布的了
目前为止，我们的估计是无偏（unbiased）的，也就是说随着样本N的增加，我们最终将收敛到积分的精确解

但是蒙特卡洛估算是有偏（biased）的，也就是说生成的样本并不完全随机，而是向特定值或者方向倾斜
这类**有偏蒙特卡洛估算**的特点是收敛速度更快，以更快的速率趋近精确解，但是由于它的偏倚性，可能永远无法收敛到精确解
所以这又回到了图形学的“大胆”问题，只要看着是对的就是对的
所以对于这个我们也是可以接受的了，这种情况下我们会将每个样本乘以或除以相应的pdf再求和

关于蒙特卡洛积分，我们就不再多赘述了，还有一点就是对于“随机”的生成
默认情况下，每个样本都是完全的(伪)随机分布
但是通过利用semi-random Sequence（半随机序列）的特定属性，我们可以生成**具有随机性同时具有特殊性**的样本向量
这个是用低偏差序列生成蒙特卡洛样本的过程称为**Quasi-Monte Carlo integration（拟蒙特卡洛积分）**，它具有更快的收敛速度，性能比较好（这也是对于Realtime我们想要的特点）
比如：对**low-discrepancy sequences**（低偏差序列）进行蒙特卡洛积分，生成的随机样本分布更为均匀
![390x214](assets/3.IBL_image_28.png)

**重要性采样**
基于上边对蒙特卡洛的认识，有一种可用于加速收敛的特性：**重要性采样**
具体到环境间接光照就是：
            针对镜面反射现象，反射的方向受限于BRDF Lobe，Lobe的尺寸由Roughness决定，那么lobe以外的范围任何采样都和镜面反射无关。所以将采样范围聚焦到Lobe附近->这就导致蒙特卡洛估算产生了偏差（bias）

**重要性采样的核心原理如下**：在由Roughness限定的区域内，围绕微表面的half vector生成采样vector
通过将蒙特卡洛采样和低偏序列结合，运用重要性采样对采样向量施加偏置，我们就获得了极快的收敛速度

#### Low-discrepancy sequence - 低偏序列
本节中，我们将基于拟蒙特卡洛（Quasi-Monte Carlo）方法生成的随机低偏序列，通过重要性采样对间接光照反射方程的镜面反射部分进行预计算

这个所用的序列为Holger Dammertz[Holger Dammertz](https://holger.dammertz.org/stuff/notes_HammersleyOnHemisphere.html)所详述的Hammersley Sequence 它是基于Van der Corput sequence的 
**Van der Corput sequence**是把十进制数字的二进制表示围绕着它的小数镜像而得的（sequence which mirrors a decimal binary representation around its decimal point.）

借助一些位操作的trick，我们可以在shader中高效的生成Van der Corput sequence，这样我们就可以使用它得到一个Hammersley Sequence所有样本N中的第i个样本
```cpp
//gives us the low-discrepancy sample i of the total sample set of size N.
float RadicalInverse_VdC(uint bits) 
{
    bits = (bits << 16u) | (bits >> 16u);
    bits = ((bits & 0x55555555u) << 1u) | ((bits & 0xAAAAAAAAu) >> 1u);
    bits = ((bits & 0x33333333u) << 2u) | ((bits & 0xCCCCCCCCu) >> 2u);
    bits = ((bits & 0x0F0F0F0Fu) << 4u) | ((bits & 0xF0F0F0F0u) >> 4u);
    bits = ((bits & 0x00FF00FFu) << 8u) | ((bits & 0xFF00FF00u) >> 8u);
    return float(bits) * 2.3283064365386963e-10; // / 0x100000000
}
// ----------------------------------------------------------------------------
vec2 Hammersley(uint i, uint N)
{
    return vec2(float(i)/float(N), RadicalInverse_VdC(i));
}  
```

不过并不是所有OpenGL版本都支持位操作，例如webgl，gles2.0，在这种设备上我们需要不依赖位运算进行计算：
```cpp
//if Driven don't support bit op, code like this:
float VanDerCorput(uint n, uint base)
{
    float invBase = 1.0 / float(base);
    float denom   = 1.0;
    float result  = 0.0;
    //犹豫旧硬件的glsl的loop循环限制，这里遍历了所有可能的32位
    for(uint i = 0u; i < 32u; ++i)
    {
        if(n > 0u)
        {
            denom   = mod(float(n), 2.0);
            result += denom * invBase;
            invBase = invBase / 2.0;
            n       = uint(float(n) / 2.0);
        }
    }

    return result;
}
// ----------------------------------------------------------------------------
vec2 HammersleyNoBitOps(uint i, uint N)
{
    return vec2(float(i)/float(N), VanDerCorput(i, 2u));
}

```

#### GGX Importance Sample - GGX重要性采样
有别于蒙特卡洛的纯随机/均匀的在半球Ω生成采样样本
在这里我们使用**GGX重要性采样**：
            **根据表面Roughness，生成偏向微表面half vector可能反射方向的样本**
            
采样过程和之前漫反射部分类似，在Loop中：
- 生成一个随机低偏序列值
- 用这个值在切线空间生成样本vector
- 将样本vector从切线空间转到世界空间，并对场景的Radiance采样

```cpp
const uint SAMPLE_COUNT = 4096u; 
for(uint i = 0u; i < SAMPLE_COUNT; ++i) 
{ 
    vec2 Xi = Hammersley(i, SAMPLE_COUNT); 
}
```

为了构建样本vector，我们还需要某种方法来定向和偏向样本vector来使得它们偏向在特定Roughness下镜面高光的lobe
这里我们使用理论章节的NDF，将GGX NDF结合Epic提出的球形采样vector中处理：
```cpp
//Xi = 低偏序列值
vec3 ImportanceSampleGGX(vec2 Xi, vec3 N, float roughness)
{
    float a = roughness*roughness;//前边提到过，根据迪士尼的观察，Roughness平方后效果更好

    float phi = 2.0 * PI * Xi.x;
    float cosTheta = sqrt((1.0 - Xi.y) / (1.0 + (a*a - 1.0) * Xi.y));
    float sinTheta = sqrt(1.0 - cosTheta*cosTheta);

    //球面坐标到笛卡尔坐标系
    vec3 H;
    H.x = cos(phi) * sinTheta;
    H.y = sin(phi) * sinTheta;
    H.z = cosTheta;

    // from tangent-space vector to world-space sample vector
    vec3 up        = abs(N.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);
    vec3 tangent   = normalize(cross(up, N));
    vec3 bitangent = cross(N, tangent);

    vec3 sampleVec = tangent * H.x + bitangent * H.y + N * H.z;
    return normalize(sampleVec);
    //得到样本向量大体围绕着预估的微表面的Half Vector
}
```

整体生成样本的方法搞定，最终完成PreFiltering的Shader类似下边这样：
```cpp
#version 330 core
out vec4 FragColor;
in vec3 localPos;

uniform samplerCube environmentMap;
uniform float roughness;

const float PI = 3.14159265359;

float RadicalInverse_VdC(uint bits);
vec2 Hammersley(uint i, uint N);
vec3 ImportanceSampleGGX(vec2 Xi, vec3 N, float roughness);

void main()
{       
    vec3 N = normalize(localPos);    
    vec3 R = N;
    vec3 V = R;

    const uint SAMPLE_COUNT = 1024u;
    float totalWeight = 0.0;   
    vec3 prefilteredColor = vec3(0.0);     
    for(uint i = 0u; i < SAMPLE_COUNT; ++i)
    {
        vec2 Xi = Hammersley(i, SAMPLE_COUNT);
        vec3 H  = ImportanceSampleGGX(Xi, N, roughness);
        vec3 L  = normalize(2.0 * dot(V, H) * H - V);

        float NdotL = max(dot(N, L), 0.0);
        if(NdotL > 0.0)
        {
            prefilteredColor += texture(environmentMap, L).rgb * NdotL;
            totalWeight      += NdotL;
        }
    }
    //记得权重
    prefilteredColor = prefilteredColor / totalWeight;

    FragColor = vec4(prefilteredColor, 1.0);
}  
```

####  Capturing pre-filter mipmap levels
接下来要做的就是将PreFiltering的结果按照不同的Roughness存在Cubemap的不同层Mipmap中
```cpp
prefilterShader.use();
prefilterShader.setInt("environmentMap", 0);
prefilterShader.setMat4("projection", captureProjection);
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_CUBE_MAP, envCubemap);

glBindFramebuffer(GL_FRAMEBUFFER, captureFBO);
unsigned int maxMipLevels = 5;//最大Mip层级

//按照Mip层数从高到低，Roughness从低到高的顺序存储
for (unsigned int mip = 0; mip < maxMipLevels; ++mip)
{
    // reisze framebuffer according to mip-level size.
    //mip层数每增加一级，分辨率减半
    unsigned int mipWidth  = 128 * std::pow(0.5, mip);
    unsigned int mipHeight = 128 * std::pow(0.5, mip);
    
    glBindRenderbuffer(GL_RENDERBUFFER, captureRBO);
    glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, mipWidth, mipHeight);
    glViewport(0, 0, mipWidth, mipHeight);
    
    float roughness = (float)mip / (float)(maxMipLevels - 1);
    prefilterShader.setFloat("roughness", roughness);
    
    //CubeMap
    for (unsigned int i = 0; i < 6; ++i)
    {
        prefilterShader.setMat4("view", captureViews[i]);
        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, 
                               GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, prefilterMap, mip);//记得指定mip等级

        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
        renderCube();
    }
}
glBindFramebuffer(GL_FRAMEBUFFER, 0);  
```

如果直接将第一级Mip作为Skybox显示，效果类似下边这样：
`vec3 envColor = textureLod(environmentMap, WorldPos, 1.2).rgb;`
![468x429](assets/3.IBL_image_29.png)

随着Mip级数增加，预处理的Cubemap将会越来越模糊
#### IBL-PreFiltering问题解决
PreFiltering的环境贴图大部分情况下都是正常的，但是也会出现一些问题，我们把常见的问题说说看

##### 接缝
因为在存储PreFiltering结果时我们按照粗糙度越高Mip层级越高的顺序存储，在Roughness比较高时对应的就是分辨率比较低的Mip层级
默认情况下OpenGL不会对Cubemap立方体面之间进行线性插值，而此时刚好对应的Lobe也是范围比较大的，因此接缝就会比较明显
![317x277](assets/3.IBL_image_30.png)
你可以启用`GL_TEXTURE_CUBE_MAP_SEAMLESS`给Cubemap正确的过滤选项
```cpp
glEnable(GL_TEXTURE_CUBE_MAP_SEAMLESS);
```

对于UE的天空盒接缝，也是同样的道理，你可以使用ddx，ddy计算指定mip解决 [18. ddx、ddy](../../../../../【7.CouseNote】/【根据作者分类】/BenCloward/ShaderGraph%20Basic/18.%20ddx、ddy.md)

##### 亮点
![353x296](assets/3.IBL_image_31.png)
亮点出现的原因是当镜面反射的光强度变化大，也就是说高频信息比较多时，进行卷积的采样数量不足以反应这些高频信息
解决方法最简单的就是增加采样量

还有一种方法可以解决，是Chetan Jag提出来的 [Chetan Jag](https://chetanjags.wordpress.com/2015/08/26/image-based-lighting/)
            可以在预过滤卷积时，不直接采样环境贴图，而是基于积分的 PDF 和粗糙度采样环境贴图的 mipmap ，以减少伪像
```cpp
float D   = DistributionGGX(NdotH, roughness);
float pdf = (D * NdotH / (4.0 * HdotV)) + 0.0001; 

float resolution = 512.0; // resolution of source cubemap (per face)
float saTexel  = 4.0 * PI / (6.0 * resolution * resolution);
float saSample = 1.0 / (float(SAMPLE_COUNT) * pdf + 0.0001);

float mipLevel = roughness == 0.0 ? 0.0 : 0.5 * log2(saSample / saTexel); 
```
采样mipmap时记得给cubemap开启三线性过滤
```cpp
glBindTexture(GL_TEXTURE_CUBE_MAP, envCubemap); 
glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
```


### 2.PreComputed BRDF
接下来我们实际解决拆分后积分的右边部分，即BRDF部分的预计算

首先是对BRDF公式的表达降维，这部分我们在开头的拆分思想中已经说过，就不对LearnOpenGL部分的拆分推导进行赘述了
我们直接看拆分后的公式：
![519x46](assets/3.IBL_image_32.png)
- ωo·h 就是cosθi，这里将点乘显式的写出来了
- F0就是R0，即基础反射率

拆分后的公式就是一个关于θ和α的公式，这样我们就可以预计算把结果存在一张LUT中了，这里的LUT被称为**BRDF预积分图**

让我们看看如何预计算
```cpp
//input:θ, roughness
//用于计算与光线视角和粗糙度相关的 BRDF (双向反射分布函数) 的积分结果
//使用了基于 GGX 模型的几何遮蔽与菲涅尔效应进行采样
vec2 IntegrateBRDF(float NdotV, float roughness)
{
    vec3 V;
    V.x = sqrt(1.0 - NdotV*NdotV);
    V.y = 0.0;
    V.z = NdotV;

    float A = 0.0;
    float B = 0.0;

    vec3 N = vec3(0.0, 0.0, 1.0);

    const uint SAMPLE_COUNT = 1024u;
    for(uint i = 0u; i < SAMPLE_COUNT; ++i)
    {
        vec2 Xi = Hammersley(i, SAMPLE_COUNT);//生成低偏差序列
        vec3 H  = ImportanceSampleGGX(Xi, N, roughness);//GGX重要性采样生成H
        vec3 L  = normalize(2.0 * dot(V, H) * H - V);

        float NdotL = max(L.z, 0.0);
        float NdotH = max(H.z, 0.0);
        float VdotH = max(dot(V, H), 0.0);

        if(NdotL > 0.0)//如果NdotL>0那么光线在考虑范围
        {
            float G = GeometrySmith(N, V, L, roughness);//G项
            float G_Vis = (G * VdotH) / (NdotH * NdotV);
            float Fc = pow(1.0 - VdotH, 5.0);//F0
            
            //A和B是最终的BRDF输出，它们通过加权的方式分别计算菲涅尔反射项和几何项的贡献
            A += (1.0 - Fc) * G_Vis;
            B += Fc * G_Vis;
        }
    }
    
    //取平均
    A /= float(SAMPLE_COUNT);
    B /= float(SAMPLE_COUNT);
    
    return vec2(A, B);
}
// ----------------------------------------------------------------------------
void main() 
{
    vec2 integratedBRDF = IntegrateBRDF(TexCoords.x, TexCoords.y);
    FragColor = integratedBRDF;
}

float GeometrySchlickGGX(float NdotV, float roughness)
{
    float a = roughness;
    float k = (a * a) / 2.0;//这里的k使用的是IBL的k，区分于直接光照的((a+1)*(a+1))/8

    float nom   = NdotV;
    float denom = NdotV * (1.0 - k) + k;

    return nom / denom;
}
// ----------------------------------------------------------------------------
//计算并返回 GGX 微面模型的几何遮蔽项，考虑了视角和光线方向的几何效应
float GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness)
{
    float NdotV = max(dot(N, V), 0.0);
    float NdotL = max(dot(N, L), 0.0);
    float ggx2 = GeometrySchlickGGX(NdotV, roughness);
    float ggx1 = GeometrySchlickGGX(NdotL, roughness);

    return ggx1 * ggx2;
}  
```

为了存储BRDF预积分图，我们生成一张512x512的Texture，然后使用一个FrameBuffer在NDC屏幕空间四边形shader运行，渲染到Attachment中
```cpp
//1.Create Texture
unsigned int brdfLUTTexture;
glGenTextures(1, &brdfLUTTexture);

// pre-allocate enough memory for the LUT texture.
glBindTexture(GL_TEXTURE_2D, brdfLUTTexture);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RG16F, 512, 512, 0, GL_RG, GL_FLOAT, 0);//Epic推荐使用16位float
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);//ClampToEdge防止边缘采样的伪像
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);

//2.RenderToAttachment
glBindFramebuffer(GL_FRAMEBUFFER, captureFBO);
glBindRenderbuffer(GL_RENDERBUFFER, captureRBO);
glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, 512, 512);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, brdfLUTTexture, 0);//指定Attachment为上边创建的Texture

glViewport(0, 0, 512, 512);//设置ViewPort到textureSize
brdfShader.use();
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
RenderQuad();//在NDC屏幕空间四边形shader

glBindFramebuffer(GL_FRAMEBUFFER, 0);
```

得到的结果类似下边这样：
![213x214](assets/3.IBL_image_33.png)


### 3.完成镜面反射IBL
拆分两部分的预计算都解决了，接下来我们就根据分割求和近似法重建镜面反射IBL

首先是输入，上个阶段预计算的两张图
```cpp
uniform samplerCube prefilterMap; 
uniform sampler2D brdfLUT;
```

接下来就是如何采样这两张图

对于**PreFiltering的环境HDRmap**，我们使用反射向量采样
```cpp

    vec3 R = reflect(-V, N);   

    const float MAX_REFLECTION_LOD = 4.0;//指定const的最大mip层数，这里给了5层（0~4）
    
    //根据Roughness选择适合的mip层级
    vec3 prefilteredColor = textureLod(prefilterMap, R,  roughness * MAX_REFLECTION_LOD).rgb;    

```

对于**预积分BRDF图**，我们使用Roughness和法线和Vew的夹角θ采样
```cpp

vec3 F = FresnelSchlickRoughness(max(dot(N, V), 0.0), F0, roughness); 
vec2 envBRDF = texture(brdfLUT, vec2(max(dot(N, V), 0.0), roughness)).rg;

//同漫反射IBL部分代码，加入Roughness修正粗糙非金属表面Fresnel过强的问题
vec3 fresnelSchlickRoughness(float cosTheta, vec3 F0, float roughness) 
{ 
    return F0 + (max(vec3(1.0 - roughness), F0) - F0) * pow(1.0 - cosTheta, 5.0); 
}
```

完整的镜面反射IBL
```cpp
//Lighting Term * BRDF Term 
vec3 specular = prefilteredColor * (F * envBRDF.x + envBRDF.y);

```


## 3.IBL
结合漫反射和镜面反射的IBL，一个完整间接光的IBL类似下边这样：
```cpp
vec3 F = FresnelSchlickRoughness(max(dot(N, V), 0.0), F0, roughness);

vec3 kS = F;
vec3 kD = 1.0 - kS;
kD *= 1.0 - metallic;     

vec3 irradiance = texture(irradianceMap, N).rgb;
vec3 diffuse    = irradiance * albedo;

const float MAX_REFLECTION_LOD = 4.0;
vec3 prefilteredColor = textureLod(prefilterMap, R,  roughness * MAX_REFLECTION_LOD).rgb;   
vec2 envBRDF  = texture(brdfLUT, vec2(max(dot(N, V), 0.0), roughness)).rg;
vec3 specular = prefilteredColor * (F * envBRDF.x + envBRDF.y);

vec3 ambientIBL = (kD * diffuse + specular) * ao; 
```
