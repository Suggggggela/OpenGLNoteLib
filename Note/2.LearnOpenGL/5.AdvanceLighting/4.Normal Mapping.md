
前边我们获取法线都是拿的顶点法线，通过法线我们可以做出很好的光照效果了
了解次时代游戏流程的大家可能知道法线贴图这张图，它允许我们通过高面数的模型烘焙出法线信息到一张贴图，将这张贴图应用到经过拓扑的低面数模型上，可以达到高面数的效果
![[assets/4.Normal Mapping_image_1.png|495x277]]
这节我们就了解一下法线贴图

## 1.法线贴图
首先我们思考一下，如何给一个平面plane渲染出墙壁一样凹凸的光照效果呢？
因为plane是一个平面，它顶点的法线自然也是同一方向的，如果我们不使用顶点的法线而是引入一张贴图获取法线信息呢？
这正是法线贴图做的事情
法线贴图存储着信息正是物体表面不同位置的法向，它为每个Fragment提供一个Normal

### 贴图存储法线
法线的范围是-1~1的，而贴图通道的范围是0~1，所以我们需要进行映射
```cpp
vec3 rgb_normal = normal * 0.5 + 0.5; // 从 [-1,1] 转换至 [0,1]
```

法线的方向大部分都偏向z轴，既（0,0,1）
因为我们需要用上边的映射，所以存储到贴图中，各个分量`*0.5+0.5`后的颜色就是（0.5，0.5，1）
对应到0~255的颜色中（125,125,255）大约就是下边这个颜色
![[assets/4.Normal Mapping_image_2.png]]

这个颜色正是我们常看到法线贴图的大部分颜色
![[assets/4.Normal Mapping_image_3.png|213x213]]

所以你可以看到一些艺术家，甚至有在ps中旁边放一个色板手绘法线的，比如这个 
https://www.youtube.com/watch?v=D0tD0ZzOH4I&list=LL&index=160&t=379s

### 世界空间使用法线贴图
我们可以直接采样法线贴图看看
```cpp
// 从法线贴图范围[0,1]获取法线 
normal = texture(normalMap, fs_in.TexCoords).rgb; 
// 将法线向量转换为范围[-1,1] 
normal = normalize(normal * 2.0 - 1.0); [...] 

// 像往常那样处理光照...
```
效果类似下边这样：
![[assets/4.Normal Mapping_image_4.png|412x326]]
可以看到灯光的效果已经不是平的了

但是如果这时把plane旋转一下，到朝y正方向而不是朝着z轴正方向，效果就会出错了
![[assets/4.Normal Mapping_image_5.png|406x286]]
![[assets/4.Normal Mapping_image_6.png|413x260]]

出现这个问题是因为法线的方向直接当做世界空间法线用的，所以是绝对的
当plane时朝z轴正方向时刚好是正确的，但当plane翻转角度之后，法线还是之前的方向，并没有改变


## 2.切线空间
### 切线空间
切线空间是以物体顶点的切线、副切线、法线组成的空间
每个顶点都有自己的切线空间
这个空间原点是顶点本身，z轴是法线方向，x轴是切线方向，y轴是副切线方向（一般通过前两者叉乘）
![[assets/4.Normal Mapping_image_7.png]]

**切线空间法线固定朝向z轴**，解决上边plane旋转后光照结果出错的一种方法是通过一个矩阵把法线从切线空间转换到其他空间进行光照计算
### TBN矩阵
这个转换矩阵叫做TBN矩阵，T=tangent切线，B=bitangent副切线，N=normal法线，通过这三个向量可以构建这个矩阵
接下来我们看看如何计算这些向量

首先TBN三个向量的位置关系如图
![[assets/4.Normal Mapping_image_8.png]]
其中T和B两个方向和uv的方向对齐
我们可以找到u和v的两个变化量delta，分别为∆U2 ∆V2，他们与uv也就是TB的方向相同
这两个变化量和另一条边E2组成的三角形的线性组合可以用TB描述：E2 = ∆U2T + ∆V2B
如图：
![[assets/4.Normal Mapping_image_9.png]]
E1也是同理：E1 = ∆U1T + ∆V1B
我们也可以通过坐标系的xyz描述：
![[assets/4.Normal Mapping_image_10.png|516x84]]
其中：
- E是两个向量位置的差
-  ∆U 和  ∆V是uv的差
- 需要求解的：T  B

通过矩阵乘法的方式表示出来就是下边这样：
![[assets/4.Normal Mapping_image_11.png|566x69]]
左右都乘以∆U ∆V的逆矩阵：
![[assets/4.Normal Mapping_image_12.png|614x72]]
以上就可以求解T B了
逆矩阵可以变化为1/矩阵的行列式，再乘以它的伴随矩阵(Adjugate Matrix)
![[assets/4.Normal Mapping_image_13.png]]

到此为止我们就可以通过三角形的两条边E2 E1和uv计算出T 和 B了


接下里我们看个实际例子

```cpp
// positions
glm::vec3 pos1(-1.0, 1.0, 0.0);
glm::vec3 pos2(-1.0, -1.0, 0.0);
glm::vec3 pos3(1.0, -1.0, 0.0);
glm::vec3 pos4(1.0, 1.0, 0.0);
// texture coordinates
glm::vec2 uv1(0.0, 1.0);
glm::vec2 uv2(0.0, 0.0);
glm::vec2 uv3(1.0, 0.0);
glm::vec2 uv4(1.0, 1.0);
// normal vector
glm::vec3 nm(0.0, 0.0, 1.0);

//E1 E2 deltaU deltaV
glm::vec3 edge1 = pos2 - pos1;
glm::vec3 edge2 = pos3 - pos1;
glm::vec2 deltaUV1 = uv2 - uv1;
glm::vec2 deltaUV2 = uv3 - uv1;

//calculate T B

//triangle1
GLfloat f = 1.0f / (deltaUV1.x * deltaUV2.y - deltaUV2.x * deltaUV1.y);

tangent1.x = f * (deltaUV2.y * edge1.x - deltaUV1.y * edge2.x);
tangent1.y = f * (deltaUV2.y * edge1.y - deltaUV1.y * edge2.y);
tangent1.z = f * (deltaUV2.y * edge1.z - deltaUV1.y * edge2.z);
tangent1 = glm::normalize(tangent1);

bitangent1.x = f * (-deltaUV2.x * edge1.x + deltaUV1.x * edge2.x);
bitangent1.y = f * (-deltaUV2.x * edge1.y + deltaUV1.x * edge2.y);
bitangent1.z = f * (-deltaUV2.x * edge1.z + deltaUV1.x * edge2.z);
bitangent1 = glm::normalize(bitangent1);

//triangle2同理
...

```

接下来我们就可以将这些计算出数据传到shader中构建TBN矩阵
```cpp
#version 330 core 
layout (location = 0) in vec3 position; 
layout (location = 1) in vec3 normal; 
layout (location = 2) in vec2 texCoords; 
layout (location = 3) in vec3 tangent; 
layout (location = 4) in vec3 bitangent;

void main()
{
    [...]
    //先将他们变换到worldspace，然后构建TBN
    vec3 T = normalize(vec3(model * vec4(tangent, 0.0)));
    vec3 B = normalize(vec3(model * vec4(bitangent, 0.0)));
    vec3 N = normalize(vec3(model * vec4(normal, 0.0)));
    mat3 TBN = mat3(T, B, N)
}
```

### 实际的法线贴图使用
上边只是一些理论知识，在实际中我们只需要切线和法线，副切线可以通过前两者叉乘获得
关于光照计算，我们现在有了TBN矩阵，可以随意的进行空间变换
一般计算光照有以下两种策略：
- 使用**TBN矩阵**将法线从切线空间转换到世界空间，在世界空间计算光照
- 使用**TBN的逆矩阵**将其他向量转换到切线空间，然后在切线空间计算光照

#### 世界空间法线

```cpp
//VS
out VS_OUT { 
...
mat3 TBN; } vs_out;

void main()
{
    ...
    vs_out.TBN = mat3(T, B, N);
}

//FS
in VS_OUT {
...
mat3 TBN; } fs_in;

void main()
{
    normal = texture(normalMap, fs_in.TexCoords).rgb;//sample normalmap
    normal = normalize(normal * 2.0 - 1.0);//remap to 0~1
    normal = normalize(fs_in.TBN * normal);//transform form tangentspace to worldspace

    //Calculate Lighting
    ...
}
```

#### 切线空间法线

```cpp
//VS
//注意这里使用的是transpose，转置矩阵（对于正交矩阵，转置矩阵=逆矩阵）
//inverse会有同样的结果但是性能更差
vs_out.TBN = transpose(mat3(T, B, N));

//FS
void main()
{
    vec3 normal = texture(normalMap, fs_in.TexCoords).rgb;
    normal = normalize(normal * 2.0 - 1.0);

    //transform other vector from world to tangent space
    vec3 lightDir = fs_in.TBN * normalize(lightPos - fs_in.FragPos);
    vec3 viewDir = fs_in.TBN * normalize(viewPos - fs_in.FragPos);
    
    //Calculate Lighting
    [...]
}
```


在切线空间计算光照可以优化为在VS转换向量空间，也就是不传递tbn的逆矩阵而是直接在vs中计算好切线空间的其他向量，传递给fs，这对于切线空间的法线是可行的
但是第一种就不可以，因为采样出来的法线对于每个Fragment都是不同的，无法在vs中进行
例如：
```cpp
out VS_OUT{
    vec3 FragPos;
    vec2 TexCoords;
    vec3 TangentLightPos;
    vec3 TangentViewPos;
    vec3 TangentFragPos;
} vs_out;

uniform vec3 lightPos;
uniform vec3 viewPos;

[...]

void main()
{
    [...]
    mat3 TBN = transpose(mat3(T, B, N));
    vs_out.TangentLightPos = TBN * lightPos;
    vs_out.TangentViewPos = TBN * viewPos;
    vs_out.TangentFragPos = TBN * vec3(model * vec4(position, 0.0));
}
```


### 正交化TBN
当法线贴图应用到表面时，将切线平均化通常能带来更平滑的效果
但是这样做就会使TBN可能不互相垂直，那么TBN就不是正交矩阵了
我们可以通过Gram-Schmidt process的正交化数学技巧让TBN正交化
```cpp
vec3 T = normalize(vec3(model * vec4(tangent, 0.0)));
vec3 N = normalize(vec3(model * vec4(normal, 0.0)));
// re-orthogonalize T with respect to N
T = normalize(T - dot(T, N) * N);
// then retrieve perpendicular vector B with the cross product of T and N
vec3 B = cross(T, N);

mat3 TBN = mat3(T, B, N)
```

## 3.Assimp自动计算切线副切线
在实际使用时我们很少自己计算切线
对于加载模型的库，Assimp可以在加载时自动计算，所以在shader中也就是通过layout拿到VertexAttribute就可以了

```cpp
//在加载时可以通过flag配置加载时，aiProcess_CalcTangentSpace会自动计算每个顶点切线和副切线
const aiScene* scene = importer.ReadFile( path, aiProcess_Triangulate | aiProcess_FlipUVs | aiProcess_CalcTangentSpace );

//获取自动计算的切线
vector.x = mesh->mTangents[i].x; 
vector.y = mesh->mTangents[i].y; 
vector.z = mesh->mTangents[i].z; 
vertex.Tangent = vector;
```

有时候自动计算切线也会出问题，比如镜像模型上的纹理表面时也镜像了另一半uv，Assimp不考虑这个镜像操作，结果就会出问题



## 4.例子
CPU端我们通过RenderQuad方法计算渲染plane的数据，shader中选择在切线空间计算光照
```cpp
//CPU
unsigned int quadVAO = 0;
unsigned int quadVBO;
void renderQuad()
{
    if (quadVAO == 0)
    {
        // positions
        glm::vec3 pos1(-1.0f,  1.0f, 0.0f);
        glm::vec3 pos2(-1.0f, -1.0f, 0.0f);
        glm::vec3 pos3( 1.0f, -1.0f, 0.0f);
        glm::vec3 pos4( 1.0f,  1.0f, 0.0f);
        // texture coordinates
        glm::vec2 uv1(0.0f, 1.0f);
        glm::vec2 uv2(0.0f, 0.0f);
        glm::vec2 uv3(1.0f, 0.0f);  
        glm::vec2 uv4(1.0f, 1.0f);
        // normal vector
        glm::vec3 nm(0.0f, 0.0f, 1.0f);

        // calculate tangent/bitangent vectors of both triangles
        glm::vec3 tangent1, bitangent1;
        glm::vec3 tangent2, bitangent2;
        // triangle 1
        // ----------
        glm::vec3 edge1 = pos2 - pos1;
        glm::vec3 edge2 = pos3 - pos1;
        glm::vec2 deltaUV1 = uv2 - uv1;
        glm::vec2 deltaUV2 = uv3 - uv1;

        float f = 1.0f / (deltaUV1.x * deltaUV2.y - deltaUV2.x * deltaUV1.y);

        tangent1.x = f * (deltaUV2.y * edge1.x - deltaUV1.y * edge2.x);
        tangent1.y = f * (deltaUV2.y * edge1.y - deltaUV1.y * edge2.y);
        tangent1.z = f * (deltaUV2.y * edge1.z - deltaUV1.y * edge2.z);

        bitangent1.x = f * (-deltaUV2.x * edge1.x + deltaUV1.x * edge2.x);
        bitangent1.y = f * (-deltaUV2.x * edge1.y + deltaUV1.x * edge2.y);
        bitangent1.z = f * (-deltaUV2.x * edge1.z + deltaUV1.x * edge2.z);

        // triangle 2
        // ----------
        edge1 = pos3 - pos1;
        edge2 = pos4 - pos1;
        deltaUV1 = uv3 - uv1;
        deltaUV2 = uv4 - uv1;

        f = 1.0f / (deltaUV1.x * deltaUV2.y - deltaUV2.x * deltaUV1.y);

        tangent2.x = f * (deltaUV2.y * edge1.x - deltaUV1.y * edge2.x);
        tangent2.y = f * (deltaUV2.y * edge1.y - deltaUV1.y * edge2.y);
        tangent2.z = f * (deltaUV2.y * edge1.z - deltaUV1.y * edge2.z);


        bitangent2.x = f * (-deltaUV2.x * edge1.x + deltaUV1.x * edge2.x);
        bitangent2.y = f * (-deltaUV2.x * edge1.y + deltaUV1.x * edge2.y);
        bitangent2.z = f * (-deltaUV2.x * edge1.z + deltaUV1.x * edge2.z);


        float quadVertices[] = {
            // positions            // normal         // texcoords  // tangent                          // bitangent
            pos1.x, pos1.y, pos1.z, nm.x, nm.y, nm.z, uv1.x, uv1.y, tangent1.x, tangent1.y, tangent1.z, bitangent1.x, bitangent1.y, bitangent1.z,
            pos2.x, pos2.y, pos2.z, nm.x, nm.y, nm.z, uv2.x, uv2.y, tangent1.x, tangent1.y, tangent1.z, bitangent1.x, bitangent1.y, bitangent1.z,
            pos3.x, pos3.y, pos3.z, nm.x, nm.y, nm.z, uv3.x, uv3.y, tangent1.x, tangent1.y, tangent1.z, bitangent1.x, bitangent1.y, bitangent1.z,

            pos1.x, pos1.y, pos1.z, nm.x, nm.y, nm.z, uv1.x, uv1.y, tangent2.x, tangent2.y, tangent2.z, bitangent2.x, bitangent2.y, bitangent2.z,
            pos3.x, pos3.y, pos3.z, nm.x, nm.y, nm.z, uv3.x, uv3.y, tangent2.x, tangent2.y, tangent2.z, bitangent2.x, bitangent2.y, bitangent2.z,
            pos4.x, pos4.y, pos4.z, nm.x, nm.y, nm.z, uv4.x, uv4.y, tangent2.x, tangent2.y, tangent2.z, bitangent2.x, bitangent2.y, bitangent2.z
        };
        // configure plane VAO
        glGenVertexArrays(1, &quadVAO);
        glGenBuffers(1, &quadVBO);
        glBindVertexArray(quadVAO);
        glBindBuffer(GL_ARRAY_BUFFER, quadVBO);
        glBufferData(GL_ARRAY_BUFFER, sizeof(quadVertices), &quadVertices, GL_STATIC_DRAW);
        glEnableVertexAttribArray(0);
        glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 14 * sizeof(float), (void*)0);
        glEnableVertexAttribArray(1);
        glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 14 * sizeof(float), (void*)(3 * sizeof(float)));
        glEnableVertexAttribArray(2);
        glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 14 * sizeof(float), (void*)(6 * sizeof(float)));
        glEnableVertexAttribArray(3);
        glVertexAttribPointer(3, 3, GL_FLOAT, GL_FALSE, 14 * sizeof(float), (void*)(8 * sizeof(float)));
        glEnableVertexAttribArray(4);
        glVertexAttribPointer(4, 3, GL_FLOAT, GL_FALSE, 14 * sizeof(float), (void*)(11 * sizeof(float)));
    }
    glBindVertexArray(quadVAO);
    glDrawArrays(GL_TRIANGLES, 0, 6);
    glBindVertexArray(0);
}

```



```cpp
//VS
#version 330 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec3 aNormal;
layout (location = 2) in vec2 aTexCoords;
layout (location = 3) in vec3 aTangent;
layout (location = 4) in vec3 aBitangent;
//vertex attributes have been calculated in cpu

out VS_OUT {
    vec3 FragPos;
    vec2 TexCoords;
    vec3 TangentLightPos;
    vec3 TangentViewPos;
    vec3 TangentFragPos;
} vs_out;

uniform mat4 projection;
uniform mat4 view;
uniform mat4 model;

uniform vec3 lightPos;
uniform vec3 viewPos;


void main()
{
    vs_out.FragPos = vec3(model * vec4(aPos, 1.0));   
    vs_out.TexCoords = aTexCoords;
    
    mat3 normalMatrix = transpose(inverse(mat3(model)));
    vec3 T = normalize(normalMatrix * aTangent);
    vec3 N = normalize(normalMatrix * aNormal);
    T = normalize(T - dot(T, N) * N);
    vec3 B = cross(N, T);
    
    mat3 TBN = transpose(mat3(T, B, N));
    
    //calculate light in tangentsapce
    //so transform other vectors to tangent space in vertexshader
    vs_out.TangentLightPos = TBN * lightPos;
    vs_out.TangentViewPos  = TBN * viewPos;
    vs_out.TangentFragPos  = TBN * vs_out.FragPos;
        
    gl_Position = projection * view * model * vec4(aPos, 1.0);
}



//FS
#version 330 core
out vec4 FragColor;

in VS_OUT {
    vec3 FragPos;
    vec2 TexCoords;
    vec3 TangentLightPos;
    vec3 TangentViewPos;
    vec3 TangentFragPos;
} fs_in;

uniform sampler2D diffuseMap;
uniform sampler2D normalMap;

uniform vec3 lightPos;
uniform vec3 viewPos;

void main()
{           
     // obtain normal from normal map in range [0,1]
    vec3 normal = texture(normalMap, fs_in.TexCoords).rgb;
    // transform normal vector to range [-1,1]
    normal = normalize(normal * 2.0 - 1.0);  // this normal is in tangent space
   
    // get diffuse color
    vec3 color = texture(diffuseMap, fs_in.TexCoords).rgb;
    // ambient
    vec3 ambient = 0.1 * color;
    // diffuse
    vec3 lightDir = normalize(fs_in.TangentLightPos - fs_in.TangentFragPos);
    float diff = max(dot(lightDir, normal), 0.0);
    vec3 diffuse = diff * color;
    // specular
    vec3 viewDir = normalize(fs_in.TangentViewPos - fs_in.TangentFragPos);
    vec3 reflectDir = reflect(-lightDir, normal);
    vec3 halfwayDir = normalize(lightDir + viewDir);  
    float spec = pow(max(dot(normal, halfwayDir), 0.0), 32.0);

    vec3 specular = vec3(0.2) * spec;
    FragColor = vec4(ambient + diffuse + specular, 1.0);
}
```
![[assets/4.Normal Mapping_image_14.png]]