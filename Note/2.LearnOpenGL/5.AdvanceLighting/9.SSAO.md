
SSAO是常用的屏幕空间AO解决方案，这节我们将自己实现一个SSAO

## 1.SSAO
Ambient Lighting环境光，他被认为是场景中总体光照的一个固定常量，被用来模拟光的散射
现实中的光是任意方向的，并且随着时间光的强度会发生改变，其中一种就是AO
他的模拟思路是通过褶皱、孔洞等墙面附近，让墙面变暗的方法来模拟AO

![456x271](assets/9.SSAO_image_1.png)
SSAO全称就是ScreenSpaceAO，是一种屏幕空间做法，最早出现在孤岛危机上（没错就是显卡危机）
SSAO的核心原理是：
- 对于Screen-filled Quad铺满屏幕的Quad上的每个像素，都会根据周围深度值计算一个遮蔽因子(Occlusion Factor)
- 这个Occlusion Factor之后会被用来减少或者抵消像素的环境光照分量
- Occlusion Factor是通过采样像素周围球形Kernel的多个深度样本和当前像素深度对比得到的(高于像素深度的就是Factor)

如下图，灰色部分的小球代表符合OcclusionFactor的样本，灰色的小球越多，那么代表它受到的环境光就越少
![387x209](assets/9.SSAO_image_2.png)

很显然，这样计算的质量和样本的数量直接相关：
- 样本太少，计算精度就不够，太少的话就会产生叫做banding的效果(带状的效果)
- 样本太多，性能又吃不消

为了解决这个问题，我们可以在采样Kernel中引入一些随机性来减少需要采样的样本数
比如：随机地旋转每个像素采样Kernel
当然，这么做也是有代价的，这样会造成一些noisy，我们需要再模糊一下结果来解决
![638x241](assets/9.SSAO_image_3.png)

Crytek在孤岛危机的SSAO中使用的是球形Kernel，这样会造成平面看起来灰蒙蒙的（对于屏幕固定有一半样本在内部），具体的样子类似下边这样：
![481x308](assets/9.SSAO_image_4.png)

为了解决这个发灰的问题，我们改用半球采样，而且这个半球是沿着表面法向量方向的半球，类似下边这样：
![400x209](assets/9.SSAO_image_5.png)
通过法线方向的外半球采样，就可以很好的解决内部固定部分被计算到Factor中，进而导致发灰的问题
这一节我们要实现的SSAO就是基于这个实现的
ref： https://john-chapman-graphics.blogspot.com/2013/01/ssao-tutorial.html

## 2.实现SSAO
### Sample Buffers
SampleBuffer作为我们存放需要获取信息的buffer
想要确定每个像素的OcclusionFactor，我们需要：
- Position
- Normal
- Albedo
- Sample Kernel
- random rotation for sample kernel


和Deferred Rendering的思路相同，我们使用MRT特性在一个shader中输出多个内容，存放这些需要的信息
```cpp
#version 330 core
layout (location = 0) out vec4 gPosition;
layout (location = 1) out vec3 gNormal;
layout (location = 2) out vec3 gAlbedo;

in vec2 TexCoords;
in vec3 FragPos;
in vec3 Normal;

void main()
{    
    gPosition = FragPos;//viewspace pos
    gNormal = normalize(Normal);
    gAlbedo.rgb = vec3(0.95);
}
```



gPostionDepth这个Texture Attachment的设置如下：
```cpp
glGenTextures(1, &gPositionDepth); 
glBindTexture(GL_TEXTURE_2D, gPositionDepth); 
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGBA, GL_FLOAT, NULL);
//注意，是GL_FLOAT，线性深度的范围0.1~50.0
//如果不想用浮点格式，需要通过除以远平面进行Normalize

glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); 
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); 
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); 
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
//ClampToEdge保证不会采样到uv以外的深度
```

### Normal-oriented hemisphere-法向半球
接下来就是生成当前像素的法向半球进行Kernel Sample了
我们知道切线空间中法线是指向z方向的，所以在切线空间中生成这个半球
```cpp
std::uniform_real_distribution<float> randomFloats(0.0, 1.0); // random floats between [0.0, 1.0]
std::default_random_engine generator;
std::vector<glm::vec3> ssaoKernel;
for (unsigned int i = 0; i < 64; ++i)
{
    //前提：切线空间
    //将xy方向从-1~1映射到0~1，就是半球而非整个球了
    //z方向为法线方向，所以这个sample沿着法线对齐
    glm::vec3 sample(
    randomFloats(generator) * 2.0 - 1.0, 
    randomFloats(generator) * 2.0 - 1.0, 
    randomFloats(generator)
    );
    sample  = glm::normalize(sample);
    sample *= randomFloats(generator);
    ssaoKernel.push_back(sample);  
}
```

以上的半球sample是均匀分布的，我们可以偏移sample的位置，让靠近像素的sample多一些，这样就靠近原点分布一些
```cpp
GLfloat scale = GLfloat(i) / 64.0; 
scale = lerp(0.1f, 1.0f, scale * scale);
sample *= scale;
ssaoKernel.push_back(sample); 
```
经过这样处理的sample分布可以参考下图：
![531x159](assets/9.SSAO_image_6.png)


### Random Kernel Rotation-随机Kernel旋转
接下来我们将sample kernel应用随机的旋转

我们不会为每个像素都创建一个随机旋转向量，因为那样性能太烂了
可以创建一个小的随机旋转向量texture，然后将其平铺在screen上

创建这个Texture的方法如下
```cpp
std::vector<glm::vec3> ssaoNoise; 
for (unsigned int i = 0; i < 16; i++) 
{
    //沿着z方向即法线方向旋转，所以z=0 
    glm::vec3 noise( 
        randomFloats(generator) * 2.0 - 1.0, 
        randomFloats(generator) * 2.0 - 1.0, 
        0.0f); 
    ssaoNoise.push_back(noise); 
}

unsigned int noiseTexture; 
glGenTextures(1, &noiseTexture);
glBindTexture(GL_TEXTURE_2D, noiseTexture);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA16F, 4, 4, 0, GL_RGB, GL_FLOAT, &ssaoNoise[0]);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
//因为是平铺到Screen上的Texture，这里使用Repeat配置  
```

### SSAO Shader

SSAO是屏幕空间做法，所以我们先创建一个FrameBufferObject存放这阶段的内容来提供给后续使用
```cpp
unsigned int ssaoFBO;
glGenFramebuffers(1, &ssaoFBO);  
glBindFramebuffer(GL_FRAMEBUFFER, ssaoFBO);
  
unsigned int ssaoColorBuffer;
glGenTextures(1, &ssaoColorBuffer);
glBindTexture(GL_TEXTURE_2D, ssaoColorBuffer);
//SSAO的结果是一个单通道的灰度值，所以Texture设置为GL_RED即可
glTexImage2D(GL_TEXTURE_2D, 0, GL_RED, SCR_WIDTH, SCR_HEIGHT, 0, GL_RED, GL_FLOAT, NULL);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
  
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoColorBuffer, 0);
```

计算SSAO的过程类似下边这样：
```cpp

// geometry pass: render stuff into G-buffer
glBindFramebuffer(GL_FRAMEBUFFER, gBuffer);
    [...]
glBindFramebuffer(GL_FRAMEBUFFER, 0);  
  
  
// SSAO pass：use G-buffer to render SSAO texture
glBindFramebuffer(GL_FRAMEBUFFER, ssaoFBO);
    glClear(GL_COLOR_BUFFER_BIT);    
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_2D, gPosition);
    glActiveTexture(GL_TEXTURE1);
    glBindTexture(GL_TEXTURE_2D, gNormal);
    glActiveTexture(GL_TEXTURE2);
    glBindTexture(GL_TEXTURE_2D, noiseTexture);
    shaderSSAO.use();
    
    //SendKernelSamplesToShader
    ...
    
    shaderSSAO.setMat4("projection", projection);
    RenderQuad();
glBindFramebuffer(GL_FRAMEBUFFER, 0);
  
  
// lighting pass: render scene lighting
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
shaderLightingPass.use();
...
glActiveTexture(GL_TEXTURE3);
glBindTexture(GL_TEXTURE_2D, ssaoColorBuffer);
...
RenderQuad();

```

计算SSAO的Shader类似下边：
```cpp
#version 330 core
out float FragColor;
in vec2 TexCoords;

uniform sampler2D gPosition;
uniform sampler2D gNormal;
uniform sampler2D texNoise;

uniform vec3 samples[64];
uniform mat4 projection;

//我们希望这个随机旋转VectorTexture平铺在Screen上
//屏幕的平铺噪声纹理会根据屏幕分辨率除以噪声大小的值来决定
const vec2 noiseScale = vec2(Screen_Width / 4.0, Screen_Height / 4.0);

void main()
{
    vec3 fragPos = texture(gPosition, TexCoords).xyz; 
    vec3 normal = texture(gNormal, TexCoords).rgb; 
    vec3 randomVec = texture(texNoise, TexCoords * noiseScale).xyz;
    
    //TBN
        //Gramm-Schmidt process，格拉姆施密特创建正交biasis
        //根据随机旋转向量倾斜构建切线
        //TBN不需要和物体表面完全对齐
    vec3 tangent = normalize(randomVec - normal * dot(randomVec, normal)); 
    vec3 bitangent = cross(normal, tangent); 
    mat3 TBN = mat3(tangent, bitangent, normal);
    
    float occlusion = 0.0;
    //kernelSize一般为1~64
    for(int i=0; i<kernelSize; ++i)
    {
        vec3 samplePos = TBM * samples[i]; //把sample转到切线空间
        samplePos = fragPos + sample * radius; //radius = sample有效取样半径
    
        vec4 offset = vec4(samplePos, 1.0);
        offset      = projection * offset;    // from view to clip-space
        offset.xyz /= offset.w;               // perspective divide -> normalized device coordinates
        offset.xyz  = offset.xyz * 0.5 + 0.5; // remap to 0~1
        
        //使用offset的xy采样ViewSpacePosition来检索z
        //得到的结果就是以view视角看到samplePos的深度（第一个未被occlusion的fragment）
        float sampleDepth = -texture(gPositon, offset.xy).z;
        
        //比较当前sample的Depth和存的fragment深度，如果样本深度>fragment深度，就代表occlusion了
        
        //因为在表面边缘附近的fragment进行occlusion计算时，会考虑测试behind的深度值
        //behind的值不应该被考虑进来，所以我们可以通过rangeCheck解决
        //如果深度值在sample的radius范围内，就对occlusion做出贡献
        //smoothstep可以让第三个参数在第一二个参数的范围获得0~1d的平滑过渡，这样超出radius部分就不会产生截断的感觉了
        float rangeCheck = smoothstep(0.0, 1.0, radius / abs(fragPos.z - sampleDepth));
        occlusion += (sampleDepth >= samplePos.z + bias ? 1.0 : 0.0) * rangeCheck;
    }
    
    //最后normalize一下occlusion的贡献值
    occlusion = 1.0 - (occlusion / kernelSize);
    
    FragColor = occlusion;
    //你也可以通过幂函数进行调整
    //FragColor = pow(occlusion, AOStrength);
}

```

### Blur 
到此为止我们已经可以计算出occlusion的部分了
但是这还不够完美，因为平铺到屏幕的旋转向量texture导致的repeat还是比较明显
最后就是模糊这部分结果，让效果更加可接受一点

首先还是创建一个FBO存放Blur的结果以供后边使用
```cpp
unsigned int ssaoBlurFBO, ssaoColorBufferBlur;
glGenFramebuffers(1, &ssaoBlurFBO);
glBindFramebuffer(GL_FRAMEBUFFER, ssaoBlurFBO);
glGenTextures(1, &ssaoColorBufferBlur);
glBindTexture(GL_TEXTURE_2D, ssaoColorBufferBlur);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RED, SCR_WIDTH, SCR_HEIGHT, 0, GL_RED, GL_FLOAT, NULL);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoColorBufferBlur, 0);

```

因为旋转向量texture已经提供了一致的随机性，我们可以利用这个特性进行简单的模糊
- 遍历SSAO结果周围-2~2的texel，对结果进行采样，采样量和旋转向量textureSize一致
- 根据textureSize对每个texel的uv进行offset，然后采样累加，最后再取平均

```cpp
#version 330 core
out float FragColor;
  
in vec2 TexCoords;
  
uniform sampler2D ssaoInput;

void main() {
    vec2 texelSize = 1.0 / vec2(textureSize(ssaoInput, 0));
    float result = 0.0;
    for (int x = -2; x < 2; ++x) 
    {
        for (int y = -2; y < 2; ++y) 
        {
            vec2 offset = vec2(float(x), float(y)) * texelSize;
            result += texture(ssaoInput, TexCoords + offset).r;
        }
    }
    FragColor = result / (4.0 * 4.0);
}  

```

### Lighting Pass
计算出occlusion之后就可以应用到光照计算中了
SSAO结果体现在环境光部分
```cpp
#version 330 core
out vec4 FragColor;

in vec2 TexCoords;

uniform sampler2D gPosition;
uniform sampler2D gNormal;
uniform sampler2D gAlbedo;
uniform sampler2D ssao;

struct Light {
    vec3 Position;
    vec3 Color;
    
    float Linear;
    float Quadratic;
};
uniform Light light;

void main()
{             
    // retrieve data from gbuffer
    vec3 FragPos = texture(gPosition, TexCoords).rgb;
    vec3 Normal = texture(gNormal, TexCoords).rgb;
    vec3 Diffuse = texture(gAlbedo, TexCoords).rgb;
    float AmbientOcclusion = texture(ssao, TexCoords).r;
    
    // then calculate lighting as usual
    vec3 ambient = vec3(0.3 * Diffuse * AmbientOcclusion);
    vec3 lighting  = ambient; 
    vec3 viewDir  = normalize(-FragPos); // viewpos is (0.0.0)
    // diffuse
    vec3 lightDir = normalize(light.Position - FragPos);
    vec3 diffuse = max(dot(Normal, lightDir), 0.0) * Diffuse * light.Color;
    // specular
    vec3 halfwayDir = normalize(lightDir + viewDir);  
    float spec = pow(max(dot(Normal, halfwayDir), 0.0), 8.0);
    vec3 specular = light.Color * spec;
    // attenuation
    float distance = length(light.Position - FragPos);
    float attenuation = 1.0 / (1.0 + light.Linear * distance + light.Quadratic * distance * distance);
    diffuse *= attenuation;
    specular *= attenuation;
    lighting += diffuse + specular;

    FragColor = vec4(lighting, 1.0);
}

```


## 3.测试
![](assets/9.SSAO_video_1.mp4)


## Ref
- 通过深度重建位置： https://mynameismjp.wordpress.com/2010/09/05/position-from-depth-3/
- 
