
## 1.DynamicRange，LDR，HDR
//以下的内容直接从百人的笔记复制
- **Dynamic Range**（动态范围）=最高亮度/最低亮度
- **HDR**= High Dynamic Range
- **LDR** = Low Dynamic Range
- **ToneMapping**：将超高的动态范围（HDR）转换到我们日常显示的屏幕上的低动态范围（LDR）的过程
- 一些小芝士：
   - 因为不同的厂家生产的屏幕亮度（物理）实际上是不统一的，那么我们在说LDR时，它是一个0到1范围的值，对应到不同的屏幕上就是匹配当前屏幕的最低亮度（0）和最高亮度（1）
   - 自然界中的亮度差异是非常大的。例如，蜡烛的光强度大约为15，而太阳光的强度大约为10w。这中间的差异是非常大的，有着超级高的动态范围。 
   - 我们日常使用的屏幕，其最高亮度是经过一系列经验积累的，所以使用、用起来不会对眼睛有伤害；但自然界中的，比如我们直视太阳时，实际上是会对眼睛产生伤害的。
### LDR
- 8位精度
   - 对于8位精度的补充：8位 = 28= 256（0~255）
- 单通道0-1
- 常用LDR图片存储的格式有jpg/png等
- 常用DCC工具中的拾色器、一般的图片、电脑屏幕都是LDR
   - 例如拾色器中0-255（256）
### HDR
- 远高于8位精度
- 单通道可以超过1
- 常用HDR图片存储的格式有hdr/tif/exr/raw等（其中很多是相机常用格式）
- HDRI、真实世界
### 补充：相机是如何将HDR映射到LDR的
- 首先将曝光值进行计算，映射到相机可以感应的范围
   - 受光圈、快门、传感器的灵敏度等影响
- 然后把这个值输入为线性的值，存储到图片中（一般为raw格式）
- 之后会经过一个变化（LUT），通过白平衡、色彩校正、色调映射、伽马校正这个过程，最后的结果烘焙成LUT（pbr中LUT的图，就是这个过程的结果）
- 每个相机厂商的LUT格式不太一样


简单的说，就是0~1的范围无法很好的表现真实的世界，因为真实的世界亮度的范围是很大的
于是就有了HDR相关的需求，但是显示器并不能显示超过1的部分
于是ToneMapping就出现了，它可以通过一些曲线将HDR映射到LDR
这样一来，两个问题就都解决了

## 2.Float FrameBuffer
当一个帧缓冲的颜色缓冲的内部格式被设定成了`GL_RGB16F`, `GL_RGBA16F`, `GL_RGB32F` 或者`GL_RGBA32F`时，这些帧缓冲被叫做浮点帧缓冲(Floating Point Framebuffer)
浮点帧缓冲可以存储超过0.0到1.0范围的浮点值，所以非常适合HDR渲染

创建一个Float FrameBuffer类似下边这样
```cpp
glBindTexture(GL_TEXTURE_2D, colorBuffer); 
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_FLOAT, NULL);
//默认的FrameBuffer每个通道为8位
//一般HDR渲染使用的FrameBuffer使用每个通道16位就够了，除非对精度的要求很高，可以使用32
```

我们可以绑定这个用于HDR渲染的FrameBuffer进行光照计算，然后再通过一个简单的TextureSampleShader采样FrameBuffer的ColorBuffer
伪代码类似下边这样：
```cpp
//绑定HDR FrameBuffer，这个FrameBuffer颜色值可以超过1
glBindFramebuffer(GL_FRAMEBUFFER, hdrFBO);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);  
// 渲染场景
//这里渲染一个隧道，在隧道尽头放强度很亮的的灯
...
glBindFramebuffer(GL_FRAMEBUFFER, 0);

// 使用一个不同的着色器将HDR颜色缓冲渲染至2D铺屏四边形上
hdrShader.Use();
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, hdrColorBufferTexture);
RenderQuad();
```
效果类似下边这样![[assets/6.HDR_image_1.png]]
可以看到最亮的地方已经完全糊成一片了
这是因为我们目前为止只解决了第一个问题，虽然FloatFrameBuffer的颜色值可以超过1，但是最终采样的ColorBuffer依然是0~1的，结果就是最亮部分都接近1了，完全分不清细节

## 3.ToneMapping
ToneMapping用于将HDR映射到LDR区间
关于ToneMapping的不同算法、历史之类就不多赘述了，需要的可以看以下的笔记
[2.7 LDR和HDR](../../../../../【7.CouseNote】/【TA100】/T/2.7%20LDR和HDR.md)
我们这里看看之前笔者手动在unityShader中ToneMapping不同算法的效果![[assets/6.HDR_image_2.png]]
LearnOpenGL中使用的是Reinhard的算法，我们打算将这些算法都写进去通过ImGui查看

```cpp
//---------------HDR FloatFrameBuffer----------------
unsigned int hdrFBO;
glGenFramebuffers(1, &hdrFBO);
    //color buffer
unsigned int colorBuffer;
glGenTextures(1, &colorBuffer);
glBindTexture(GL_TEXTURE_2D, colorBuffer);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGBA, GL_FLOAT, NULL);//16bit per chanel
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
    //depth buffer
unsigned int rboDepth;
glGenRenderbuffers(1, &rboDepth);
glBindRenderbuffer(GL_RENDERBUFFER, rboDepth);
glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, SCR_WIDTH, SCR_HEIGHT);
    //attachment
glBindFramebuffer(GL_FRAMEBUFFER, hdrFBO);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, colorBuffer, 0);
glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, rboDepth);
if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE)
    std::cout << "Framebuffer not complete!" << std::endl;
glBindFramebuffer(GL_FRAMEBUFFER, 0);

//-------------Light Data--------------------
// positions
std::vector<glm::vec3> lightPositions;
lightPositions.push_back(glm::vec3(0.0f, 0.0f, 49.5f)); // back light
lightPositions.push_back(glm::vec3(-1.4f, -1.9f, 9.0f));
lightPositions.push_back(glm::vec3(0.0f, -1.8f, 4.0f));
lightPositions.push_back(glm::vec3(0.8f, -1.7f, 6.0f));
// colors
std::vector<glm::vec3> lightColors;
lightColors.push_back(glm::vec3(50.0f, 50.0f, 50.0f));
lightColors.push_back(glm::vec3(0.1f, 0.0f, 0.0f));
lightColors.push_back(glm::vec3(0.0f, 0.0f, 0.2f));
lightColors.push_back(glm::vec3(0.0f, 0.1f, 0.0f));


while(Rendering)
{
    ...
    
    //-------pass0:render scene to HDR framebuffer----------------
    glBindFramebuffer(GL_FRAMEBUFFER, hdrFBO);
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
    glm::mat4 projection = glm::perspective(glm::radians(camera.Zoom), (GLfloat)SCR_WIDTH / (GLfloat)SCR_HEIGHT, 0.1f, 100.0f);
    glm::mat4 view = camera.GetViewMatrix();
    shader.use();
    shader.setMat4("projection", projection);
    shader.setMat4("view", view);
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_2D, woodTexture);
    // set lighting uniforms
    for (unsigned int i = 0; i < lightPositions.size(); i++)
    {
        shader.setVec3("lights[" + std::to_string(i) + "].Position", lightPositions[i]);
        shader.setVec3("lights[" + std::to_string(i) + "].Color", lightColors[i]);
    }
    shader.setVec3("viewPos", camera.Position);
    // render tunnel
    glm::mat4 model = glm::mat4(1.0f);
    model = glm::translate(model, glm::vec3(0.0f, 0.0f, 25.0));
    model = glm::scale(model, glm::vec3(2.5f, 2.5f, 27.5f));
    shader.setMat4("model", model);
    shader.setInt("inverse_normals", true);
    renderCube();
    glBindFramebuffer(GL_FRAMEBUFFER, 0);
    
    //-------pass1:render HDR framebuffer to screen----------------
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
    hdrShader.use();
    glActiveTexture(GL_TEXTURE0);
    glBindTexture(GL_TEXTURE_2D, colorBuffer);
    hdrShader.setInt("hdr", hdr);
    hdrShader.setInt("ACES", ACES);
    hdrShader.setInt("Reinhard", Reinhard);
    hdrShader.setInt("enableExposure", enableExposure);
    hdrShader.setFloat("exposure", exposure);
    renderQuad();
    
    ...
}

```



```cpp
//Sample HDRTexture FS

#version 330 core
out vec4 FragColor;

in vec2 TexCoords;

uniform sampler2D hdrBuffer;
uniform bool hdr;
uniform bool enableExposure;
uniform bool ACES;
uniform bool Reinhard;
uniform float exposure;



vec3 ReinhardToneMapping(vec3 color) 
{

    return color / (1.0f + color);
}
vec3 ReinhardToneMapping(vec3 color, float exposure) 
{

    return vec3(1.0) - exp(-color * exposure);
}


vec3 ACESToneMapping(vec3 color)
{
    const float A = 2.51f;
    const float B = 0.03f;
    const float C = 2.43f;
    const float D = 0.59f;
    const float E = 0.14f;
    
    return (color * (A * color + B)) / (color * (C * color + D) + E);
}
vec3 ACESToneMapping(vec3 color, float exposure)
{
    color *= exposure;
    const float A = 2.51f;
    const float B = 0.03f;
    const float C = 2.43f;
    const float D = 0.59f;
    const float E = 0.14f;
    
    return (color * (A * color + B)) / (color * (C * color + D) + E);
}

void main()
{             
    //const float gamma = 2.2;
    //伽马校正已经在CPU端通过OpenGLenable开启，shader中不手动矫正了

    vec3 hdrColor = texture(hdrBuffer, TexCoords).rgb;

    if(hdr)
    {
        if(!enableExposure)
        {    
            if(Reinhard)
            {
                vec3 result = ReinhardToneMapping(hdrColor);
                FragColor = vec4(result, 1.0);
            }
            else if(ACES)
            {
                vec3 result = ACESToneMapping(hdrColor);
                FragColor = vec4(result, 1.0);
            }
        }
        else
        {
            if(Reinhard)
            {
                vec3 result = ReinhardToneMapping(hdrColor,exposure);
                FragColor = vec4(result, 1.0);
            }
            else if(ACES)
            {
                vec3 result = ACESToneMapping(hdrColor,exposure);
                FragColor = vec4(result, 1.0);
            }
        }
    }
    else
    {
        //vec3 result = pow(hdrColor, vec3(1.0 / gamma));
        //FragColor = vec4(result, 1.0);
        FragColor = vec4(hdrColor, 1.0);
    }
}

```

![](assets/6.HDR_video_1.mp4)

//注：ACES的效果应该是比Reinhard的效果好的，但是这里Reinhard映射的画面颜色暗部更亮一些（雀氏是更灰的），在知乎的文章评论区中也有人问为什么实际写出了ACES效果有些不如Reinhard
//个人猜测和灯光强度有关，这个情况下灯光已经远远超过1了(50)
隧道尽头的灯光强度为50
![[assets/6.HDR_image_3.png]]

如果把尽头的灯光强度改为3，效果对比如下：
![[assets/6.HDR_image_4.png]]

## 4.Exposure
### Exposure
曝光是我们现实中使用相机会涉及的概念，引擎中涉及到PBR-Camera时也会涉及
说的白话一点就是曝光类似人眼的自适应，引擎中可以通过曝光调节明暗或者昼夜环境的光照，而不是为不同明暗场景设置不同参数的光照，这更加符合真实世界一点

### Automatic Exposure
自动曝光调整(Automatic Exposure Adjustment)或者叫人眼适应(Eye Adaptation)技术
它能够检测前一帧场景的亮度并且缓慢调整曝光参数模仿人眼使得场景在黑暗区域逐渐变亮或者在明亮区域逐渐变暗